{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "In a class I took in undergrad, the professor liked to give a weekly quiz on a random day of the week, with 4 multiple choice questions, where there were 4 possible answers of being correct. Let's suppose that I am not a very good student and don't study at all, and resolve to simply guess on all of my answers. Suppose further than 100% of my grade is determined by these quizzes (We can change this later). What are the chances I get an A? B? C? Fail the class?\n",
    "\n",
    "## A probabilistic answer\n",
    "\n",
    "We can start simple, and try and add complexity as as we go. First, we'll suppose that I am in an academic quarter system of 10 weeks, so 100% of my grade is determined by 10 quizzes with 4 questions, where each question has 4 possible answers, and only *one* of them is correct. Assuming that my guesses are truly random, they'll be independent between questions, and quizzes. The probability I make the correct answer on any one question is $\\frac{1}{4}$, since there is 1 right answer and 3 wrong ones. Each question attempt then represents a Bernoulli trial, and since my attempts on each question are independent, the probability I get $k \\in \\{0, 1, 2, 3, 4\\}$ questions right on the quiz follows a binomial distribution with $n = 4$ and $p = 0.25$. If $X = \\{ \\text{Number of questions I get right on a quiz} \\}$, then we can write the following:\n",
    "\n",
    "$$P(X = k) = {4 \\choose k } (p)^k (1-p)^{n - k}$$\n",
    "\n",
    "We can then calculate the probabilites for $k = 0, 1, ..., 4$ by hand, but we can also use `R` to do this in a couple lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The probability of getting 0 answers right is 0.316\"\n",
      "[1] \"The probability of getting 1 answers right is 0.422\"\n",
      "[1] \"The probability of getting 2 answers right is 0.211\"\n",
      "[1] \"The probability of getting 3 answers right is 0.047\"\n",
      "[1] \"The probability of getting 4 answers right is 0.004\"\n"
     ]
    }
   ],
   "source": [
    "outcomes <- c(0, 1, 2, 3, 4)\n",
    "num_trials <- 4\n",
    "probability <- 0.25\n",
    "\n",
    "for (k in outcomes) {\n",
    "    result <- dbinom(x = k, size = num_trials, prob = probability)\n",
    "    result <- round(result, 3)\n",
    "    answer <- sprintf(\"The probability of getting %d answers right is %s\", k, result)\n",
    "    print(answer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look promising. But these are *exact* probabilities. What if I wanted to know the probability I get *at least* $k$ answers right? For sample, the probability I get *at least* 3 answers right is the probability I get 3 correct, or get 4 correct. So by the addition law in probability:\n",
    "\n",
    "$$P(\\{k = 3\\} \\cup \\{k = 4\\}) = P(\\{k = 3\\}) + P(\\{k = 4\\}) + P(\\{k = 3\\} \\cap \\{k = 4\\})$$\n",
    "\n",
    "Since I can't get both 3 answers and 4 answers correct on a multiple choice quiz, the furtherst  right term vanishes. So, we can really just add the probabilities. Recall that $P(X \\leq k ) = 1 - P(X > k)$. So the probability of getting \"at least $k$ answers right\" is:\n",
    "\n",
    "$$P(X \\geq k ) = 1 - P(X < k) = 1 - P(X \\leq k - 1 )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The probability of getting at least 1 answers right is 0.684\"\n",
      "[1] \"The probability of getting at least 2 answers right is 0.262\"\n",
      "[1] \"The probability of getting at least 3 answers right is 0.051\"\n",
      "[1] \"The probability of getting at least 4 answers right is 0.004\"\n"
     ]
    }
   ],
   "source": [
    "outcomes <- c(1, 2, 3, 4)\n",
    "num_trials <- 4\n",
    "probability <- 0.25\n",
    "\n",
    "for (k in outcomes) {\n",
    "    result <- 1 - pbinom(q = k - 1, size = num_trials, prob = probability)\n",
    "    result <- round(result, 3)\n",
    "    answer <- sprintf(\"The probability of getting at least %d answers right is %s\", k, result)\n",
    "    print(answer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. So things still aren't looking great. But that's just one quiz! We have 10 quizzes. That's more chances to do well, right? Since the sum of independent and identically distributed binomial random variables is itself a binomial random variable, we can model the probabilities for $k$ answers correct across all quizzes. We have 10 quizzes with 4 questions, so we have 40 possible questions to get right. Now assuming that we have no curving, and no plus/minus grades, the cut offs for an A, B, C, and D are 90%, 80%, 70%, and 60%. Anything below 60% is an F. That means the cut offs in correct number of quiz questions are 36, 32, 28, and 24, respectively. For now, we can look at the probabilities of getting *at least* an A, B, C, or D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The probability of getting at least 24 answers right is 2.8259666799979e-06\"\n",
      "[1] \"The probability of getting at least 28 answers right is 2.84103096603872e-09\"\n",
      "[1] \"The probability of getting at least 32 answers right is 4.53526105559376e-13\"\n",
      "[1] \"The probability of getting at least 36 answers right is 0\"\n"
     ]
    }
   ],
   "source": [
    "outcomes <- c(24, 28, 32, 36)\n",
    "num_trials <- 40\n",
    "probability <- 0.25\n",
    "\n",
    "for (k in outcomes) {\n",
    "    result <- 1 - pbinom(q = k - 1, size = num_trials, prob = probability)\n",
    "    #result <- round(result, 3)\n",
    "    answer <- sprintf(\"The probability of getting at least %d answers right is %s\", k, result)\n",
    "    print(answer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good. What's the probability of failing the class? It's just the probability you get less than 24 answers right, which in R can be coded as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The probability you fail the class is 0.999999412034064'"
      ],
      "text/latex": [
       "'The probability you fail the class is 0.999999412034064'"
      ],
      "text/markdown": [
       "'The probability you fail the class is 0.999999412034064'"
      ],
      "text/plain": [
       "[1] \"The probability you fail the class is 0.999999412034064\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_fail <- pbinom(q = 24, size = num_trials, prob = probability)\n",
    "sprintf(\"The probability you fail the class is %s\", prob_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y i k e s. The probability of getting an A grade by random guessing on 10 four question quizzes is so low that R is evaluating the probability to 0. Your probability of failing is essentially 100%. Bad strategy.\n",
    "\n",
    "But let's make this more interesting. Suppose that instead of having hard cut offs, we curve the class by standardizing the scores and putting the mean at a C grade. Two standard deviations below the mean is an F, and two standard deviations above the mean is an A. Now, suppose we're in a class of 50 students, and test taking ability is essentially normally distributed. \n",
    "\n",
    "We can draw 50 students from the normal distribution with an assumed mean and standard deviation corresponding to final total quiz scores, and compute the within sample mean and standard deviation. Then, we can compute the probability we fail the class with our guessing strategy, based on the curve and the average ability of students.\n",
    "\n",
    "(NB: If you're worried about scores being above 40, we can simply round it down to 40)\n",
    "\n",
    "So let's suppose that, in the long run, quiz scores are around 28 and have a standard deviation of 5. Let's draw 50 final scores from this normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The mean score is 26'"
      ],
      "text/latex": [
       "'The mean score is 26'"
      ],
      "text/markdown": [
       "'The mean score is 26'"
      ],
      "text/plain": [
       "[1] \"The mean score is 26\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'The standard deviation is 4'"
      ],
      "text/latex": [
       "'The standard deviation is 4'"
      ],
      "text/markdown": [
       "'The standard deviation is 4'"
      ],
      "text/plain": [
       "[1] \"The standard deviation is 4\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(10)\n",
    "fifty_scores <- round(rnorm(n = 50, mean = 28, sd = 5))\n",
    "fifty_scores[fifty_scores > 40] = 40\n",
    "sprintf(\"The mean score is %s\", round(mean(fifty_scores)))\n",
    "sprintf(\"The standard deviation is %s\", round(sd(fifty_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, our new cut offs work in the following way: Within 1 standard deviation of the mean is a C, above 1 standard deviation above is a B, 1 standard deviation below is a D, 2 standard deviations above is an A, and finally, 2 standard deviations below is an F. Notice that even though we drew from a normal distribution with a mean of 28 and a standard deviation of 5, the within sample mean is 26, with a standard deviation of 4.\n",
    "\n",
    "So in this case, we get the following grading scheme, let $x$ denote someone's score\n",
    "\n",
    "$$A: x > 34 \\\\\n",
    "B: 30 < x \\leq 34\\\\\n",
    "C: 22 \\leq x \\leq 30\\\\\n",
    "D: 18 \\leq x < 22\\\\\n",
    "F: x < 18$$\n",
    "\n",
    "If it looks like it's easy to get a C in this class, that's because it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The probability you fail the class is 0.9953'"
      ],
      "text/latex": [
       "'The probability you fail the class is 0.9953'"
      ],
      "text/markdown": [
       "'The probability you fail the class is 0.9953'"
      ],
      "text/plain": [
       "[1] \"The probability you fail the class is 0.9953\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trials <- 40\n",
    "probability <- 0.25\n",
    "\n",
    "prob_fail <- pbinom(q = 17, size = num_trials, prob = probability)\n",
    "sprintf(\"The probability you fail the class is %s\", round(prob_fail, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still pretty bad, but let's see if we can be more realistic about our model. First, no student guesses entirely randomly on every single question, and no multiple choice exam has choices that are all equally probable. As anyone who has done standardized testing knows, if there are 4 multiple choice answers, usually 2 of them are \"obviously wrong\" and the difficulty is in selecting between the other two. Suppose that our hypothetical class is set up in this way, where each question has two obviously wrong answers and two seemingly correct answers, and the task is in selecting between the latter two. If this seems unrealistic, we can argue that the student at least goes to lecture and maybe does a little reading, but is otherwise just trying to \"skate by\". In this case, we might assume that the probability of selecting the right answer is 50% instead of 25%, since we are just going to randomly guess between the two \"seemingly correct\" answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'The probability you fail the class is 0.215'"
      ],
      "text/latex": [
       "'The probability you fail the class is 0.215'"
      ],
      "text/markdown": [
       "'The probability you fail the class is 0.215'"
      ],
      "text/plain": [
       "[1] \"The probability you fail the class is 0.215\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trials <- 40\n",
    "probability <- 0.50\n",
    "\n",
    "prob_fail <- pbinom(q = 17, size = num_trials, prob = probability)\n",
    "sprintf(\"The probability you fail the class is %s\", round(prob_fail, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. If you're looking to slack off, then (about) 4 times out of 5, if you can reduce each question to a guess between two seemingly right answers, and just give a total guess, you will pass a class. But if we look at the calculations below, the probability we get an $A$ is basically 0. But, the probability we get at least a $C$ grade is a surprising $\\approx 32\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The probability of getting at least 18 answers right is 0.997002775978406\"\n",
      "[1] \"The probability of getting at least 22 answers right is 0.930081002932577\"\n",
      "[1] \"The probability of getting at least 30 answers right is 0.121491905808092\"\n",
      "[1] \"The probability of getting at least 34 answers right is 0.00436300692871394\"\n"
     ]
    }
   ],
   "source": [
    "outcomes <- c(18, 22, 30, 34)\n",
    "num_trials <- 40\n",
    "probability <- 0.65\n",
    "\n",
    "for (k in outcomes) {\n",
    "    result <- 1 - pbinom(q = k - 1, size = num_trials, prob = probability)\n",
    "    #result <- round(result, 3)\n",
    "    answer <- sprintf(\"The probability of getting at least %d answers right is %s\", k, result)\n",
    "    print(answer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this really says is that you can get away with doing very little and still pass a curved class, but in some sense, our assumptions are too restrictive and case specific. I've never heard of a class weighting 100% of your grade on quizzes, have you?\n",
    "\n",
    "Let's complicate the model. We are going to do a few things. First, let's create a more realistic testing environment. Let's imagine that the class is composed of 7 quizzes, a midterm, and a final. In most classes I've personally had, finals count for 30% to 60% of your final grade, quizzes count for between 10% to 30%, and a midterm is usually weighted about the same as a quiz. Let's choose the following grade break down:\n",
    "\n",
    "$$30\\% Quizzes + 30\\% Midterm + 40\\% Final = 100\\% Final Grade$$.\n",
    "\n",
    "For the sake of our model, we'll assume everything is multiple choice with 4 possible answers (I have seen some physics classes organized in this way). We'll say that there are five quizzes of 5 questions each(so 25 total), the midterm has 15 questions, and the final has 30 questions. In total, we have 70 multiple choice questions for this physics class. \n",
    "\n",
    "We'll also drop the assumption that final scores of the cohort are normally distributed with a fixed mean. Instead, let's actually model the abilities of students. We'll say that an $F$ student just randomly guesses on each answer, a $D$ student gets an answer right with probability 60%, a $C$ student gets an answer right with probability 70%, a $B$ student gets an answer right with probability 80%, and an $A$ student gets an answer right with probability 95%. (Why these numbers? Mostly because they match our intuition.)\n",
    "\n",
    "\n",
    "The reason for using a bell curve style of grading is we are assuming that student ability normally distributed. A normal distribution has approximately 68% of students within 1 standard deviation of the mean, 95% within two standard deviations, and 99.7% within 3 standard deviations. What we'll do is draw 50 numbers from a standard normal distribution and organize them by their standard deviation to the mean. Depending where they fall on that standard deviation, we'll map them to their ability. E.g., if a number is within 1 standard deviation of the mean, we'll map them to the $C$ student who gets answers right with probability 65%. We'll populate the class in this way, and the result should be a class that has normally distributed test taking ability. \n",
    "\n",
    "As for the grading scheme, we'll grade in this way. The top 20% of the class gets an $A$, the next 30% gets a $B$, the next 30% get a $C$, and the next 10% get a $D$ and the final 10% get an $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw students from a standard normal\n",
    "students <- rnorm(n = 50)\n",
    "\n",
    "#to hold scores\n",
    "class_quiz_scores <- c()\n",
    "class_midterm_scores <- c()\n",
    "class_final_scores <- c()\n",
    "\n",
    "#constants\n",
    "num_quiz_qs <- 25\n",
    "num_midterm_qs <- 15\n",
    "num_final_qs <- 30\n",
    "\n",
    "F_prob <- 0.25\n",
    "D_prob <- 0.60\n",
    "C_prob <- 0.70\n",
    "B_prob <- 0.80\n",
    "A_prob <- 0.95\n",
    "\n",
    "#iterate through students\n",
    "for (student in students) {\n",
    "    \n",
    "    # < -2 = F student\n",
    "    if (student < -2) {\n",
    "        \n",
    "        #simulate student scores\n",
    "        quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = F_prob)\n",
    "        midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = F_prob)\n",
    "        final_score <- rbinom(n = 1, size = num_final_qs, prob = F_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, final_score)\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # D students\n",
    "    if (student > -2 && student < -1) {\n",
    "        \n",
    "        #simulate student scores\n",
    "        quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = D_prob)\n",
    "        midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = D_prob)\n",
    "        final_score <- rbinom(n = 1, size = num_final_qs, prob = D_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, final_score)\n",
    "        }\n",
    "    \n",
    "    # C students\n",
    "    if (student > -1 && student < 1) {\n",
    "        \n",
    "        #simulate student scores\n",
    "        quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = C_prob)\n",
    "        midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = C_prob)\n",
    "        final_score <- rbinom(n = 1, size = num_final_qs, prob = C_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, final_score)\n",
    "        }\n",
    "    \n",
    "    # B students\n",
    "    if (student > 1 && student < 2) {\n",
    "        \n",
    "        #simulate student scores\n",
    "        quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = B_prob)\n",
    "        midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = B_prob)\n",
    "        final_score <- rbinom(n = 1, size = num_final_qs, prob = B_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, final_score)\n",
    "        }\n",
    "    \n",
    "    # A students\n",
    "    if (student > 2) {\n",
    "        \n",
    "        #simulate student scores\n",
    "        quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = A_prob)\n",
    "        midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = A_prob)\n",
    "        final_score <- rbinom(n = 1, size = num_final_qs, prob = A_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, final_score)\n",
    "        }\n",
    "}\n",
    "\n",
    "#weight each score for the grade\n",
    "final_grades <- (0.30 * class_quiz_scores) + (0.30 * class_midterm_scores) + (0.40 * class_final_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the quantiles. Below 10% is an $F$, between 10 and 20% is a $D$, between 20 and 50% is a $C$, between 50 and 80% is a $B$, and above 80% is an $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>10%</dt>\n",
       "\t\t<dd>12.17</dd>\n",
       "\t<dt>20%</dt>\n",
       "\t\t<dd>13.64</dd>\n",
       "\t<dt>50%</dt>\n",
       "\t\t<dd>16.55</dd>\n",
       "\t<dt>80%</dt>\n",
       "\t\t<dd>18.46</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[10\\textbackslash{}\\%] 12.17\n",
       "\\item[20\\textbackslash{}\\%] 13.64\n",
       "\\item[50\\textbackslash{}\\%] 16.55\n",
       "\\item[80\\textbackslash{}\\%] 18.46\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "10%\n",
       ":   12.1720%\n",
       ":   13.6450%\n",
       ":   16.5580%\n",
       ":   18.46\n",
       "\n"
      ],
      "text/plain": [
       "  10%   20%   50%   80% \n",
       "12.17 13.64 16.55 18.46 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile(final_grades, probs = c(0.10, 0.20, 0.50, 0.80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'There are 5 F students, 5 D students, 15 C students, 15 B students, and 10 A students'"
      ],
      "text/latex": [
       "'There are 5 F students, 5 D students, 15 C students, 15 B students, and 10 A students'"
      ],
      "text/markdown": [
       "'There are 5 F students, 5 D students, 15 C students, 15 B students, and 10 A students'"
      ],
      "text/plain": [
       "[1] \"There are 5 F students, 5 D students, 15 C students, 15 B students, and 10 A students\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cutoffs <- quantile(final_grades, probs = c(0.10, 0.20, 0.50, 0.80))\n",
    "num_F <- sum(final_grades < cutoffs[1])\n",
    "num_D <- sum(final_grades < cutoffs[2] & final_grades > cutoffs[1])\n",
    "num_C <- sum(final_grades < cutoffs[3] & final_grades > cutoffs[2])\n",
    "num_B <- sum(final_grades < cutoffs[4] &  final_grades > cutoffs[3])\n",
    "num_A <- sum(final_grades > cutoffs[4])\n",
    "\n",
    "sprintf(\"There are %s F students, %s D students, %s C students, %s B students, and %s A students\",\n",
    "        num_F, num_D, num_C, num_B, num_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially what we have done is \n",
    "\n",
    "1) Randomly generate a class of students from a normal distribution. \n",
    "\n",
    "2) Assign each student a probabilistic final score in the class based on their abilities.\n",
    "\n",
    "3) Use a deterministic cut off in the way universities sometimes do. \n",
    "\n",
    "The thing to note about the quantile cut off is that, regardless of the class performance, at least 10% of the class will recieve a failing grade. \n",
    "\n",
    "Now, what's the probability we fail the class? We will compute this as a long term average. We'll calculate our score seperate from the class generating process (as a function of the probability we get the answer right), and append it to the final scores to calculate our cut offs. Then we'll note if we failed the class or not. We'll repeat this process an extremely large number of times. The proportion of times we failed the class will then give us the probability we fail the class.\n",
    "\n",
    "The below code block just takes the work we've done so far and converts it into a function that we can use to simulate a lot of classroom outcomes. In each case, we count the number of times we failed, got a C, B, or A, and divide it by the number of simulations we did to compute the probability.\n",
    "\n",
    "(NB: This function is NOT optimized, and is very slow, but it gets the job done.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_prob <- 0.25\n",
    "D_prob <- 0.60\n",
    "C_prob <- 0.70\n",
    "B_prob <- 0.80\n",
    "A_prob <- 0.95\n",
    "\n",
    "estimator <- function(iter = 100, my_prob = 0.50, num_stud = 50){\n",
    "    \n",
    "    #to hold results\n",
    "    times_F <- 0\n",
    "    times_D <- 0\n",
    "    times_C <- 0\n",
    "    times_B <- 0\n",
    "    times_A <- 0\n",
    "    count <- 0\n",
    "    \n",
    "    for (i in 1:iter) {\n",
    "        #iterate through students\n",
    "        #draw students from a standard normal\n",
    "        students <- rnorm(n = num_stud)\n",
    "        \n",
    "        #to hold scores, needs to be refreshed every time. \n",
    "        \n",
    "        class_quiz_scores <- c()\n",
    "        class_midterm_scores <- c()\n",
    "        class_final_scores <- c()\n",
    "        \n",
    "        \n",
    "        for (student in students) {\n",
    "    \n",
    "            # < -2 = F student\n",
    "            if (student < -2) {\n",
    "        \n",
    "                #simulate student scores\n",
    "                quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = F_prob)\n",
    "                midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = F_prob)\n",
    "                final_score <- rbinom(n = 1, size = num_final_qs, prob = F_prob)\n",
    "        \n",
    "                #append student scores\n",
    "                class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "                class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "                class_final_scores <- c(class_final_scores, final_score)\n",
    "            }\n",
    "    \n",
    "            # D students\n",
    "            if (student > -2 & student < -1) {\n",
    "        \n",
    "                #simulate student scores\n",
    "                quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = D_prob)\n",
    "                midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = D_prob)\n",
    "                final_score <- rbinom(n = 1, size = num_final_qs, prob = D_prob)\n",
    "        \n",
    "                #append student scores\n",
    "                class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "                class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "                class_final_scores <- c(class_final_scores, final_score)\n",
    "                }\n",
    "    \n",
    "            # C students\n",
    "            if (student > -1 & student < 1) {\n",
    "        \n",
    "                #simulate student scores\n",
    "                quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = C_prob)\n",
    "                midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = C_prob)\n",
    "                final_score <- rbinom(n = 1, size = num_final_qs, prob = C_prob)\n",
    "        \n",
    "                #append student scores\n",
    "                class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "                class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "                class_final_scores <- c(class_final_scores, final_score)\n",
    "                }\n",
    "    \n",
    "            # B students\n",
    "            if (student > 1 & student < 2) {\n",
    "        \n",
    "                #simulate student scores\n",
    "                quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = B_prob)\n",
    "                midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = B_prob)\n",
    "                final_score <- rbinom(n = 1, size = num_final_qs, prob = B_prob)\n",
    "        \n",
    "                #append student scores\n",
    "                class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "                class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "                class_final_scores <- c(class_final_scores, final_score)\n",
    "                }\n",
    "    \n",
    "            # A students\n",
    "            if (student > 2) {\n",
    "        \n",
    "                #simulate student scores\n",
    "                quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = A_prob)\n",
    "                midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = A_prob)\n",
    "                final_score <- rbinom(n = 1, size = num_final_qs, prob = A_prob)\n",
    "        \n",
    "                #append student scores\n",
    "                class_quiz_scores <- c(class_quiz_scores, quiz_score)\n",
    "                class_midterm_scores <- c(class_midterm_scores, midterm_score)\n",
    "                class_final_scores <- c(class_final_scores, final_score)\n",
    "                }\n",
    "        }\n",
    "\n",
    "            \n",
    "        \n",
    "            #simulate my scores\n",
    "        my_quiz_score <- rbinom(n = 1, size = num_quiz_qs, prob = my_prob)\n",
    "        my_midterm_score <- rbinom(n = 1, size = num_midterm_qs, prob = my_prob)\n",
    "        my_final_score <- rbinom(n = 1, size = num_final_qs, prob = my_prob)\n",
    "        \n",
    "        #append student scores\n",
    "        class_quiz_scores <- c(class_quiz_scores, my_quiz_score)\n",
    "        class_midterm_scores <- c(class_midterm_scores, my_midterm_score)\n",
    "        class_final_scores <- c(class_final_scores, my_final_score)\n",
    "        \n",
    "        #calculate final grades according to weighting scheme\n",
    "        final_grades <- (0.30 * class_quiz_scores) + (0.30 * class_midterm_scores) + (0.40 * class_final_scores)\n",
    "\n",
    "        #calculate my score\n",
    "        my_score <- (0.30 * my_quiz_score) + (0.30 * my_midterm_score) + (0.40 * my_final_score)\n",
    "        \n",
    "        #calculate quantiles\n",
    "        cutoffs <- quantile(final_grades, probs = c(0.10, 0.20, 0.50, 0.80))\n",
    "        \n",
    "        count <- count + 1\n",
    "        \n",
    "        if (my_score < cutoffs[1]){\n",
    "            \n",
    "            times_F <- times_F + 1\n",
    "        }\n",
    "        \n",
    "        else if (my_score < cutoffs[2] & my_score >= cutoffs[1]) {\n",
    "            \n",
    "            times_D <- times_D + 1\n",
    "        }\n",
    "        else if (my_score < cutoffs[3] & my_score >= cutoffs[2]) {\n",
    "            \n",
    "            times_C <- times_C + 1\n",
    "        }\n",
    "        else if (my_score < cutoffs[4] & my_score >= cutoffs[3]) {\n",
    "            \n",
    "            times_B <- times_B + 1\n",
    "        }\n",
    "        else if (my_score >= cutoffs[4]) {\n",
    "            \n",
    "            times_A <- times_A + 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    #calculate final probabilities\n",
    "    result_F <- times_F / iter\n",
    "    result_D <- times_D / iter\n",
    "    result_C <- times_C / iter\n",
    "    result_B <- times_B / iter\n",
    "    result_A <- times_A / iter\n",
    "    total <- times_F + times_D + times_C + times_B + times_A\n",
    "\n",
    "    sprintf(\"The probability of an F is %s, a D is %s, a C is %s, a B is %s, and an A is %s\", \n",
    "             result_F, result_D, result_C, result_B, result_A)\n",
    "    \n",
    "    return(1 - result_F)\n",
    "    #return(final_grades)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call our function and calculate the long run probability of our final grade in the class as a function of our individual probability of getting any question correct. We'll assume that we are in a class of 100 students. To get stable estimates, we'll use 5000 simulations for each probability estimate, and then plot the probability of us passing the class as a function of our ability to get a question right.\n",
    "\n",
    "(NB: The following block of code is very slow, but works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- c()\n",
    "for (i in seq(0, 1, by = 0.01)) {\n",
    "    p <- estimator(iter = 5000, my_prob = i, num_stud = 100)\n",
    "    results <- c(results, p)\n",
    "}\n",
    "\n",
    "data <- data.frame(\"probability_pass\" = results, \"prob_guess_right\" = seq(0, 1, by = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAMAAAC46dgSAAAANlBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "ggplot(data = data) +\n",
    "    geom_line(aes(x = prob_guess_right, y = probability_pass)) +\n",
    "    ylab(\"Probability of Passing\") +\n",
    "    xlab(\"Probability of Getting a Question Correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we can see pretty sharp changes in your probability of passing the class. It looks like under no circumstances is a coin-flip chance of getting any question right a useful strategy, but surprisingly, the probability of passing is actually non-zero in this curved grading scheme. But, if your probability of getting any question right is about 62.5%, then your probability of passing the class explodes to 75%. If you can get 75% of the answers right, then you're essentially garunteed to pass. These things match our intuition.\n",
    "\n",
    "Possible Model improvements:\n",
    "\n",
    "1) What's the best way to model student ability? Here we make explicit assumptions that student ability is normally distributed, and we also made explicit assumptions on about how many questions a $F, D, C, B,$ or $A$ student gets right. We might be able to add another layer of randomness here by instead drawing from a fat-tailed distribution (which is often more reflective of real life) or by adding random error to average proportion of questions a student gets right. \n",
    "\n",
    "2) Failing 10% of the class might be unrealistic. A 5% fail rate is probably more reflective of reality. Or use two cutoffs, which I have seen some professors do. Usually it goes like this - Your grade is the higher of two options: raw percentage, relative standing in the class. E.g., if my raw score is 72%, but I'm in the bottom 5% of the class, I still get a C/C- grade. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
